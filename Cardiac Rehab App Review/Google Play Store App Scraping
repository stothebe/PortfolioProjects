from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import time
import pandas as pd

# downloading chromedriver https://sites.google.com/chromium.org/driver/

s = Service("/Users/sarahhbang/chromedriver")

driver = webdriver.Chrome(service=s)

driver.get("https://play.google.com/store/apps")

print(driver.title)

first_app = driver.find_element(By.LINK_TEXT, "See more")
print(first_app.text)

search = driver.find_element(By.XPATH, "//input[@id='gbqfq']") #finding search box
search.send_keys("heart") #defining search term
search.send_keys(Keys.RETURN) # returning results

time.sleep(3)

search_button = driver.find_element(By.ID, 'gbqfb').click()
search_button = driver.find_element(By.ID, 'gbqfb').click()

time.sleep(5)


try:

    search_page = WebDriverWait(driver, 10).until(
            EC.staleness_of((first_app))  # ensure we are on the search page
         )
    time.sleep(1)
    element = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, "//div[@class = 'GzbC1b']"))  # ensure we are on the search page
         )
    time.sleep(1)

    SCROLL_PAUSE_TIME = 2  # waiting until all pages are loaded

    # Get scroll height
    last_height = driver.execute_script("return document.body.scrollHeight")
    time.sleep(SCROLL_PAUSE_TIME)

    while True:
        # Scroll down to bottom
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")

        # Wait to load page
        time.sleep(SCROLL_PAUSE_TIME)

        # Calculate new scroll height and compare with last scroll height
        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            break
        last_height = new_height

    links_apps = []
    elems = driver.find_elements(By.XPATH, "//a[@href]")
    for elem in elems:
        if "details?id" in elem.get_attribute("href"):
            links_apps.append((elem.get_attribute("href")))

    links_apps = list(dict.fromkeys(links_apps))


    link = []
    name = []
    description = []
    rating = []
    company = []
    for iteration in links_apps:
        try:
            driver.get(iteration)
            time.sleep(2)

            header1 = driver.find_element(By.TAG_NAME, "h1")
            descript = driver.find_element(By.XPATH, "//div[@itemprop='description']").text
            rating1 = driver.find_element(By.XPATH, '//div[@class = "BHMmbe"]').text
            company1 = driver.find_element(By.XPATH, '//a[@class = "hrTbp R8zArc"]').text
            name.append(header1.text)
            link.append(iteration)
            description.append(descript)
            rating.append(rating1)
            company.append(company1)
        except Exception as e:
            print(e)

except :
        driver.quit()


df = pd.DataFrame({'name': name, 'link': link, 'description': description, 'rating': rating, 'company':company})
df.to_csv('diditwork.csv')
print(df.head)
